# GPGPU架构

## GPGPU控制核心架构

### 线程束调度

调度在计算机中是一个常见的概念。笼统地讲，调度是指分配工作所需资源的方法。在计算机中这个“资源”可以涵盖各种层次的资源，既可以是虚拟的计算资源，如线程、进程或数据流，也可以是硬件资源，如处理器、网络连接或ALU单元。调度的目的是使得所有资源都处于忙碌状态，从而允许多个工作可以有效地同时共享资源，或达到指定的服务质量。

不同的调度策略往往会针对不同目标，例如，吞吐率最大化、响应时间最小化、最低延迟或最大化公平。这些目标在同一系统中往往是相互矛盾的，因此调度策略要实现一个权衡利弊的折中方案，这取决于用户的需求和目的。

CUDA和OpenCL编程模型可以定义任意数量的线程块和线程，线程块会被分配到可编程多处理器上（SM），由内部的流式处理器（SP）提供线程级并行。但硬件资源是有限的，每个周期只能执行若干线程，因此就引入了调度问题。早期的GPGPU多采用轮询策略来保证调度的公平性，尽管这种策略简单可行，但很多时候执行效率并不高，因此人们提出了多种改进和优化的调度策略。

#### 线程束并行、调度与发射

GPGPU中大量的线程束（warp）提供了高度的可并行性，使得它可以借助零开销线程束切换来掩盖如缓存缺失等长延时操作。理论上warp越多，并行度越高，延时掩盖效果可能会越好。但实际上这个并行度还受SM中可用的硬件资源以及每个线程所需的资源所约束，如最大线程数、最大线程块数及寄存器和共享存储器的容量。最终执行时可达到的线程并行度是由线程块、线程、寄存器和共享存储器中允许的最小并行度决定的。由于并不是所有资源都能够同时达到满载，因此对于非瓶颈的资源来说会存在一定的浪费。

当SM中有众多warp处于就绪态（或活跃）时，需要由调度器从中挑选一个，被选中的warp会在接下来的执行周期中根据它的PC发射出一条新的指令来执行。从整个SM角度看，由于调度器每个周期都可以切换它所选择的warp，不同warp的不同指令可能会细粒度地交织在一起，但同一个warp的指令仍是顺序执行的。调度器需要根据GPGPU的架构特点设计合适的策略来做出这个选择，尽可能保证SIMT执行单元不会空闲。

#### 基本调度策略

warp调度器的职责就是从就绪的warp中挑选一个或多个线程束发送给空闲的执行单元。这个过程看似简单，但由于连接了指令取指和执行两个关键步骤，调度器的选择会涉及整个GPGPU执行过程的多方面，对GPGPU的性能有着重要的影响。

关于就绪的定义，CPU中一条就绪的指令通常需要满足三个基本条件：下一条指令已经取到，指令的所有相关性都已解决，以及指令所需的执行单元可用。GPGPU中的warp也类似，根据NVIDIA对发射停顿原因的描述，主要有以下原因：

1. Pipeline busy，指令运行所需的功能单元正忙
2. Texture单元正忙
3. Constant缓存缺失，一般来说会在第一次访问时缺失
4. Instruction Fetch，指令缓存缺失，一般只有第一次运行访问容易缺失
5. Memory Throttle，有大量存储器访问操作尚未完成，为了不加剧性能耗损而阻塞访存指令下发。这种原因造成的停顿可以通过合并存储器事务来缓解
6. Memory Dependency，由于请求资源不可用或满载导致load/store无法执行，可以通过存储访问对齐和改变访问模式来缓解
7. Synchronization，等待同步指令
8. Execution Dependency，输入依赖关系还未解决，即输入值未就绪

只有消除了上述停顿原因的warp才是可以发射的。通过对这些停顿的动态统计分析，架构设计者可以获知特定内核函数性能损失的原因。例如，在存储受限型（Memory Bound）的应用中，存储依赖（memory dependency）的占比往往会很高，此时GPGPU的性能大幅受限于访存。根据分析结果，编程人员可以对内核函数的代码进行优化，另一方面，架构设计者也可以获得对微架构做进一步优化的方向。

早期的warp调度器往往采用基本的轮询（Round-Robin，RR）调度策略。它在调度过程中，对处于就绪状态的warp都赋予相同的优先级，并按照轮询的策略依次选择处于就绪状态warp的指令进行调度，完成后再切换到下一个就绪warp的指令。

与此对应的另一种策略叫GTO（Greedy-Then-Oldest），该策略允许一个warp按照贪心策略一直执行到不能执行为止，例如遭遇了缓存缺失，此时调度器再选择一个最久未调度的warp来执行，如果再次停顿则再调度其他最久未调度的warp，直到执行结束。

#### warp调度策略优化

GPGPU的执行性能与warp的调度之间关系紧密。warp调度的主要功能是选择合适的warp指令发射执行，但“合适”却很难给出具体的定义，总体上需要以改善性能和功耗为目标。合适的调度策略的设计需要综合考虑硬件设计的复杂度、开销及代码执行过程中的多种复杂情况，比如，掩盖长延时操作以提高吞吐率、发掘数据局部性以降低延时、线程执行进度的平衡等，从而获得性能和功耗的最优化。

在GPGPU架构中，数据的访存延时仍然是影响性能的主要因素，而发掘数据的**局部性**则是改善访存延时的最有效手段之一。由于SIMT架构的特点，一般来讲内核函数中往往存在两种数据局部性：**warp内局部性**（intra-warp locality）和**warp间局部性**（inter-warp locality）。当数据被一个线程访问后，如果不久之后还会被同一warp中的线程再次访问则称为warp内局部性，而如果再次访问的是其他warp中的线程则称为warp间局部性。注意这里的“再次访问”既可以是这个数据本身，也可以是相邻地址的数据，因此同时包含了时间局部性和空间局部性。

上一节中提到的轮询和GTO两种调度策略，其实就是发掘warp内局部性和warp间局部性的不同体现：轮询策略通过执行不同warp的同一条指令，较好地获得了warp间局部性；而GTO策略则更多地考虑了warp内局部性。到底哪种因素更重要、对性能的影响更大则要根据实际运行程序的特点决定。

GPGPU架构采用大规模线程的设计初衷就是希望能够利用线程的快速切换达到掩盖访问延时的目的，从而保证或提高吞吐率。但基本的轮询调度策略并不能很好地达到这一效果。在使用轮询策略时，所有warp先后进入访存指令，但访存延时可能远比所有warp进入访存指令所需的周期数多，因此会导致流水线陷入一段较长时间的空闲。即，除非有大量warp可供调度，否则很容易导致延时无法被有效掩盖，这反映出**轮询调度策略对长延时操作的容忍度不够高**。

与之相对，GTO策略则倾向于让一个warp尽快执行。当遭遇了长延时操作时，其他warp还可以有更多的指令用于掩盖延时，从而提供一定程度的改进。但**GTO策略可能会破坏warp间局部性**，在缓存较小的情况下可能会导致缓存数据重用不足甚至抖动现象，这反而拉长了平均访存延时，使得本可以避免的缓存缺失反而需要更高的线程并行度来掩盖。

因此，GPGPU的warp调度往往需要解决两方面的问题：

1. 调度策略需要能够甄别出执行过程中影响性能的主要因素
2. 调度器能以简单的硬件逻辑利用轮询和GTO策略或两者的结合取得更好的性能

两者相互依赖，调度器通过专门的硬件对某些指标进行动态统计，反馈给调度器进行策略的调整。下面介绍几个对缓存缺失、指令停顿等指标进行统计并调正调度策略的案例。

##### 利用并行性掩盖长延时操作

在GPGPU架构中，轮询和GTO调度策略都比较理想化，面对复杂情况时显示出诸多不足。基于两者的基本思想，针对长延时操作的掩盖有如下几种改进的调度策略。

1）两级轮询调度

为了解决前面提到的轮询调度策略对长延时操作容忍度不高的问题，论文[《Improving GPU performance via large warps and two-level warp scheduling》](https://dl.acm.org/doi/abs/10.1145/2155620.2155656)设计了一种两级warp调度（two-level warp scheduling）策略，它将所有warp划分为固定大小的组（fetch group），组内采用轮询策略，组间基于优先级顺序的策略进行调度。

在初始条件下，第0组优先级最高，第1组次之……。第0组将优先得到调度，当该组中所有warp依次执行到访存指令时，将该组的优先级降至最低，同时赋予第1组最高优先级，组内每个warp同样按照轮询策略调度，以此类推。调度器通过修改各组的优先级，切换到下一个优先级最高的组并执行，达到了隐藏延时、缩短流水线空闲时间的目的。

这种两级调度策略是对基本轮询调度策略的一种改进，实现起来也相对简单。该调度策略通过将各个组的长延时操作分隔开，使访存指令可以分批次更早地发射执行，将后继组的运算阶段和前置组的访存阶段重叠起来，提高了长延时操作的掩盖能力。同时组内仍采用轮询方式，让相邻warp相继执行，尽可能保证数据的空间局部性（包括组间）。

但这种方式对组规模这个超参数的设置比较敏感：当组内warp数量过少时，加载到DRAM行缓冲区的数据不能得到充分利用，且warp级并行度过低，无法掩盖数据依赖等导致的短延时操作；若组内warp数量过多，最坏情况将退化到基本轮询调度策略，对长延时操作的容忍度降低。这个阈值的选择对于不同的具体案例可能会有所不同，设计调度器时需要考虑到这一点。

2）线程块感知的两级轮询调度

与两级轮询调度策略类似，[《OWL: cooperative thread array aware scheduling techniques for improving GPGPU performance》](https://dl.acm.org/doi/abs/10.1145/2499368.2451158)同样从提高GPGPU对长延时操作的容忍能力出发，提出了另一种两级调度策略——线程块感知的两级线程束调度（CTA-aware two-level warp scheduling）。与前者不同的是，该策略兼顾了线程块间数据的分布特点而试图利用线程块间的数据局部性，所以将第一级设置为线程块级，即分组时将若干存在数据局部性的线程块分配到同一组中。相应的，下一级仍设置为线程束级，每个线程块包含若干线程束，以此作为该策略下的第二级进行调度。

线程块内的warp按照轮询策略调度执行。当前置组中所有线程束都因长延时操作而被阻塞时，调度器切换到下一组线程块并继续执行。这种方法在理念上与两级轮询调度相同，可以认为是在具体操作层面上的改进。

3）结合数据预取的两级调度策略

预取作为一种掩盖长延时访存操作的技术，被广泛应用于CPU中。但在GPGPU中，如果warp调度和预取策略配合不当，会导致需要预取warp的调度时机与当前正在执行的warp过于接近，使得延时不能被充分掩盖。

针对这一问题，[《Orchestrated scheduling and prefetching for GPGPUs》](https://dl.acm.org/doi/abs/10.1145/2485922.2485951)提出了一种预取感知的调度方式（prefetch-aware warp schedule）。它同样采用两级调度策略，但在对warp分组时将连续的warp隔开，如W0/W2/W4/W6为组0，W1/W2/W3/W5为组1。这种情况下，W0请求访问全局存储器时，对W1的预取也会发出，而W1真正被调度的时间在组0的warp全部进入停顿之后，一部分预取时间可以被组1的执行时间掩盖，从而提高预取质量。

##### 利用局部性提高片上数据复用

虽然GPGPU强调线程并行性和计算的吞吐率，但利用数据的局部性对提升性能来说也至关重要，因为当数据被加载到片上存储尤其是L1数据缓存后，如果能有效地重用这些数据，可以减少访存的延时，相对于减少了长延时访存操作的次数，这也是GPGPU中也引入了缓存的一个重要原因。

虽然缓存在通用场景下对数据重用很重要，但SM内部的L1数据缓存容量往往都很小，只有几十到几百KB规模。考虑到一个SM中巨大的线程数目，每个线程能够分配到的L1数据缓存容量往往只有几个字节，显然会带来验证的缓存冲突问题。为了能够利用缓存降低访存延时，一种方法就是通过**降低同时活跃的线程块或线程束数目来提高每个线程块或线程束所分配到的缓存容量**，进而提高L1缓存的命中率，提高GPGPU整体运行效率。这种技术也成为“限流”（throttling）技术。对于缓存敏感的内核函数来说，限流技术通过提高L1数据缓存的命中率，可能会带来良好的性能提升，同时还可以与线程束调度很好地结合。

有研究对**缓存敏感型应用**的访存行为进行了统计分析，发现warp内局部性比warp间局部性更为普遍，因此可以充分利用warp内局部性改善缓存敏感型应用的性能。传统的GTO策略虽然一定程度上利用了warp内局部性，但它缺少访存情况的主动反馈，无法指导调度器根据实际的访存情况进行策略的调整（对warp级并行度和warp内局部性做实时权衡）。

针对这一问题，[《Cache-Conscious Wavefront Scheduling》](https://ieeexplore.ieee.org/abstract/document/6493609)（AMD中称线程束为wavefront）提出了一种缓存感知的调度策略（Cache-Conscious Wavefront Scheduling，CCWS）。CCWS通过限制SM中可以发射访存指令的活跃warp数量，保证L1缓存中的数据得到更为充分有效地复用，提高访存命中率。

CCWS是一种带有反馈机制的、可动态调整的warp调度方案，其核心设计思想是，如果warp发生缓存局部性缺失，则为它提供更多的缓存资源，以降低可能复用的数据被替换出缓存的可能性。

##### warp进度分化与调度平衡

在理想情况下，GPGPU中不同warp的执行路径完全相同，执行时间也类似。但有些时候warp的执行进度也会表现出较大的差别。例如，再遭遇同步栅栏或线程分支时，不同warp的执行出现分化。由于GPGPU以线程块为粒度分配处理器资源（如寄存器文件、调度表项等），如果一个线程块中不同warp之间执行进度差异很大，先执行完成的warp就会一直等待后完成的warp而长期占用处理器资源。这不仅会导致资源闲置，还会造成可用资源不足、并行度降低等问题。因此，在warp执行进度差异较大时，平衡不同warp的执行进度对于改善GPGPU的性能来说也是一个重要的因素。

1）多调度器协同策略

前面介绍的调度策略都是针对只有一个warp调度器的情况。当SM中有多个调度器时，如果缺乏互相协同也可能导致执行过程不够高效。

2）warp动态均衡调度策略

线程执行进度的分化在一个调度器下也会出现。一个原因在于存储系统访问的不确定性，即便采用轮询调度，同一线程块内不同warp的执行进度也可能存在较大差异。另一个重要原因就是在线程同步栅栏处或在分支线程重聚的位置，执行快的warp先到达，等待执行慢的warp。但在此期间先到达的warp并不会释放器占有的硬件资源（如寄存器文件，资源的释放需要在一个线程块中所有的warp都退出了才执行），导致大量资源被闲置浪费。而且当越来越多warp到达栅栏或重聚点而不得不等待时，活跃warp数也变得越来越少而不足以掩盖长延时操作，导致流水线吞吐量明显降低。因此，需要一种动态协调warp执行进度的方法，缩小最快和最慢warp之间的执行差距。

[《CAWA: coordinated warp scheduling and cache prioritization for critical warp acceleration of GPGPU workloads》](https://dl.acm.org/doi/abs/10.1145/2872887.2750418)提出了一种基于运行时动态感知warp进度的调度策略CAWA。其中，warp的“关键性”反映的就是warp执行时间的长短，执行时间最长（即执行最慢）的一个warp就被称为关键warp，因为这个warp往往决定着当前整个线程块的执行时间。因此一个简单的方法就是给予关键warp更高的调度优先级，分配更多的硬件和时间资源给它，最大限度满足其执行需求。

为了在运行时确定一个warp是否关键，文中提出了一种称为关键度预测的度量方法来为每个warp维护一个关键性度量值。影响warp关键性的因素主要来自两方面：线程分支导致的工作负载差异和共享资源竞争引入的停顿。对于前者，当指令执行遇到分支时，不同分支路径内指令数量多数情况下是不相等的，可以直观地用指令数目作为判据之一。哪个路径的指令多，其对关键度的影响越大。对于后者，即访问共享资源发生竞争造成warp空闲等待，也增加了其跃升为关键warp的可能。综合以上两方面的影响因素，就可以得到对warp关键性的度量。

基于对warp关键度的判别，该文献提出了一种基于GTO的关键性感知warp调度策略，称为greedy Critical-Aware Warp Scheduling（gCAWS）。在GTO策略中，调度器会尽可能选择同一个warp执行，其他就绪的warp需要等待，这种策略没有考虑warp的关键性问题。gCAWS策略改进了调度选取warp的机制，每次选择关键度最高的一个warp，即给予关键warp最高的调度优先级。当关键度最高的warp有多个时，按照GTO策略选取生命周期最长的warp执行。同时，在执行阶段不断更新关键度的值，以便发现新的更为关键的warp进行调度。可以看到，gCAWS在调度上同时满足了关键warp和生命周期最长warp的急迫需求，有利于warp执行分化时的调度平衡。

### 记分牌

#### CPU与GPGPU中的数据依赖

与CPU一样，指令之间的数据依赖会对流水线的指令级并行产生影响。

简单复习一下三种数据依赖：

* 写后读（Read After Write，RAW）：真数据依赖
* 写后写（Write After Write，WAW）：输出依赖（名称依赖）
* 读后写（Write After Read，WAR）：反依赖

在CPU中，通过寄存器重命名可以解决输出依赖（WRW）和反依赖（WAR）这两种由寄存器名冲突而非真实数据传递引起的数据依赖，而真数据依赖则可以通过记分牌和Tomasulo算法检测和规避。

但GPU寄存器和功能单元数量众多，记分牌和Tomasulo算法的复杂度和硬件开销是GPU无法接受的，大量连线的成本也不容忽视。

另一方面，相较于CPU需要利用乱序执行来提高指令级并行度，GPGPU的SIMT架构指令并行度本就很高，且寄存器数量足以支持**零开销线程切换**，即使某个线程束由于数据依赖而导致停顿，线程束调度器也可以从其他线程束中找到合适的指令填充流水线，降低数据依赖对流水线性能的影响。

因此，GPGPU一般会采用warp内顺序执行、warp间乱序执行的方式来提高SIMT运算单元的硬件效率，避免乱序流水线带来的指令管理开销。但GPGPU流水线仍然需要对数据依赖进行检测和处理以保证执行结果的正确性。

#### GPGPU中的记分牌

相比CPU乱序执行流水线的记分牌需要记录功能单元（结构冒险）和寄存器（WAR、WAW）是否可用以及指令的输入数据可以从哪个功能单元旁路获取（RAW）来提高**单线程发射吞吐**，GPGPU的顺序流水线只需简单地记录功能单元和寄存器是否可用来决定是否阻塞指令的发射，通过零开销线程切换来保证**多线程发射吞吐**。

下面来探讨一下如何记录寄存器是否可用：

最简单的方式是为每个线程束寄存器分配1bit用于记录相应寄存器的的可用状态，后续存在数据依赖的指令只有当该寄存器可用时才能发射。

但这种方案存在两个问题：

* GPGPU中存在大量寄存器，给每个寄存器都分配1bit将占用大量的空间；
* 所有待发射的线程束指令在调度时需要一直查询记分牌，假设每个SM最高支持64个warp，每个warp最多访问4个操作数，那么记分牌需要提供256个端口给线程束调度器才能支持同时检查所有warp的数据依赖，会带来巨大的硬件开销。

以下是两种可行的优化方案：

##### 基于寄存器编号索引的记分牌

该方法来源于NVIDIA的一项专利。

由于记分牌主要是对指令缓冲中已解码的指令进行相关性检查，因此可以将记分牌存储空间划分为与指令缓冲中指令数目相同的区域，每个区域中包含若干条目，每个条目包含两个属性：寄存器RID（Register ID）和尺寸指示器。寄存器RID记录了该区域所对应的线程束目前正在执行的若干指令中，将要写回的目的寄存器编号；若指令中将要写回的寄存器为一个序列，尺寸指示器则负责记录该寄存器序列的长度，而RID只需要记录这个序列中的第一个寄存器的RID。这种记录方式的好处是，如果目的寄存器是连续分配和使用的，可以避免采用多个条目来记录，减少了记分牌存储空间的使用量，而这可以通过编译器中的寄存器分配算法来最大化这一可能性。研究表明，3~4个条目基本可以满足大多数应用再实际运行中的需求。

这种记分牌编码方式主要通过寄存器编码的方式替代了原来的独热码方式来识别寄存器，同时限制未完成写回的寄存器数量（如6个），从而减少记分牌存储空间的开销。

##### 基于读写屏障的软件记分牌

上述基于寄存器编号索引的硬件记分牌中，当一条新的指令准备发射时，需要搜索记分牌存储空间里对应线程束区域中的**所有条目**以检查寄存器之间的相关性。这一过程还可以通过软硬件结合的方式进一步优化，可以采用如下的软件记分牌设计：首先设计一定数量的读写屏障，借助编译器分析，显式地将存在相关性的寄存器绑定到某个读写屏障上；在运行时，目的寄存器的写操作可以直接设定绑定的读写屏障，而源寄存器的读操作需要读取绑定的读写屏障来获知该寄存器的写操作是否完成。由于这些信息由编译器提供，且能快速定位到绑定的读写屏障，因此可以节省硬件开销，并降低搜索的代价。

相比基于寄存器编号的硬件记分牌设计，这种软件记分牌设计节省了存储空间。原则上每个线程束只要维护6个写屏障和读屏障就可以避免数据竞争和冒险。另一方面，编译器通过将屏障编号编码到指令中，使得硬件记分牌只需要少量的解码逻辑就可以在运行时确定寄存器在哪个屏障中，相比纯硬件实现的记分牌，这种方式避免了查询属于该线程束的所有条目。
